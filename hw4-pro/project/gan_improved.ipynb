{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\mat}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\mattr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\matinv}[1]{\\boldsymbol {#1}^{-1}}\n",
    "\\newcommand{\\vec}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\vectr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\rvar}[1]{\\mathrm {#1}}\n",
    "\\newcommand{\\rvec}[1]{\\boldsymbol{\\mathrm{#1}}}\n",
    "\\newcommand{\\diag}{\\mathop{\\mathrm {diag}}}\n",
    "\\newcommand{\\set}[1]{\\mathbb {#1}}\n",
    "\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n",
    "\\newcommand{\\pderiv}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\bm}[1]{{\\bf #1}}\n",
    "\\newcommand{\\bb}[1]{\\bm{\\mathrm{#1}}}\n",
    "$$\n",
    "\n",
    "# Part 3: Generative Adversarial Networks\n",
    "<a id=part3></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will implement and train a generative adversarial network and apply it to the task of image generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-22T10:39:49.463010Z",
     "iopub.status.busy": "2021-01-22T10:39:49.462160Z",
     "iopub.status.idle": "2021-01-22T10:39:50.111430Z",
     "shell.execute_reply": "2021-01-22T10:39:50.111980Z"
    }
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import urllib\n",
    "import shutil\n",
    "import re\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "test = unittest.TestCase()\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-22T10:39:50.116605Z",
     "iopub.status.busy": "2021-01-22T10:39:50.115967Z",
     "iopub.status.idle": "2021-01-22T10:39:50.352290Z",
     "shell.execute_reply": "2021-01-22T10:39:50.352830Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from project.gan import *\n",
    "\n",
    "import cs3600.plot as plot\n",
    "import cs3600.download\n",
    "from hw4.answers import PART3_CUSTOM_DATA_URL as CUSTOM_DATA_URL\n",
    "\n",
    "DATA_DIR = pathlib.Path.home().joinpath('.pytorch-datasets')\n",
    "if CUSTOM_DATA_URL is None:\n",
    "    DATA_URL = 'http://vis-www.cs.umass.edu/lfw/lfw-bush.zip'\n",
    "else:\n",
    "    DATA_URL = CUSTOM_DATA_URL\n",
    "\n",
    "_, dataset_dir = cs3600.download.download_data(out_path=DATA_DIR, url=DATA_URL, extract=True, force=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `Dataset` object that will load the extraced images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-22T10:39:50.357059Z",
     "iopub.status.busy": "2021-01-22T10:39:50.356555Z",
     "iopub.status.idle": "2021-01-22T10:39:50.419033Z",
     "shell.execute_reply": "2021-01-22T10:39:50.419570Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "im_size = 64\n",
    "tf = T.Compose([\n",
    "    # Resize to constant spatial dimensions\n",
    "    T.Resize((im_size, im_size)),\n",
    "    # PIL.Image -> torch.Tensor\n",
    "    T.ToTensor(),\n",
    "    # Dynamic range [0,1] -> [-1, 1]\n",
    "    T.Normalize(mean=(.5,.5,.5), std=(.5,.5,.5)),\n",
    "])\n",
    "\n",
    "ds_gwb = ImageFolder(os.path.dirname(dataset_dir), tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, let's see what we got. You can run the following block multiple times to display a random subset of images from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-22T10:39:50.423082Z",
     "iopub.status.busy": "2021-01-22T10:39:50.422593Z",
     "iopub.status.idle": "2021-01-22T10:39:52.228975Z",
     "shell.execute_reply": "2021-01-22T10:39:52.229485Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot.dataset_first_n(ds_gwb, 50, figsize=(15,10), nrows=5)\n",
    "print(f'Found {len(ds_gwb)} images in dataset folder.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-22T10:39:52.233499Z",
     "iopub.status.busy": "2021-01-22T10:39:52.232988Z",
     "iopub.status.idle": "2021-01-22T10:39:52.257054Z",
     "shell.execute_reply": "2021-01-22T10:39:52.257567Z"
    }
   },
   "outputs": [],
   "source": [
    "x0, y0 = ds_gwb[0]\n",
    "x0 = x0.unsqueeze(0).to(device)\n",
    "print(x0.shape)\n",
    "\n",
    "test.assertSequenceEqual(x0.shape, (1, 3, im_size, im_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Nets (GANs)\n",
    "<a id=part3_2></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-22T10:39:52.742501Z",
     "iopub.status.busy": "2021-01-22T10:39:52.741883Z",
     "iopub.status.idle": "2021-01-22T10:39:52.835926Z",
     "shell.execute_reply": "2021-01-22T10:39:52.836448Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from hw4.answers import part3_gan_hyperparams\n",
    "torch.manual_seed(42)\n",
    "vanilla = False\n",
    "wgan = True\n",
    "spectral = True\n",
    "# Hyperparams\n",
    "hp = part3_gan_hyperparams()\n",
    "batch_size = hp['batch_size']\n",
    "z_dim = hp['z_dim']\n",
    "\n",
    "# Data\n",
    "dl_train = DataLoader(ds_gwb, batch_size, shuffle=True)\n",
    "im_size = ds_gwb[0][0].shape\n",
    "\n",
    "# Model\n",
    "if spectral:\n",
    "    dsc = SNDiscriminator().to(device)\n",
    "else:\n",
    "    dsc = Discriminator(im_size).to(device)\n",
    "gen = Generator(z_dim, featuremap_size=64).to(device)\n",
    "\n",
    "weights_init(dsc)\n",
    "weights_init(gen)\n",
    "\n",
    "# Optimizer\n",
    "def create_optimizer(model_params, opt_params):\n",
    "    opt_params = opt_params.copy()\n",
    "    optimizer_type = opt_params['type']\n",
    "    opt_params.pop('type')\n",
    "    return optim.__dict__[optimizer_type](model_params, **opt_params)\n",
    "\n",
    "# vanilla GAN\n",
    "if vanilla:\n",
    "    dsc_optimizer = create_optimizer(dsc.parameters(), hp['discriminator_optimizer'])\n",
    "    gen_optimizer = create_optimizer(gen.parameters(), hp['generator_optimizer'])\n",
    "elif wgan:\n",
    "    # WGAN\n",
    "    gen_optimizer = torch.optim.RMSprop(gen.parameters(), lr = 0.00005)\n",
    "    dsc_optimizer = torch.optim.RMSprop(dsc.parameters(), lr = 0.00005)\n",
    "\n",
    "elif spectral:\n",
    "    dsc_optimizer = create_optimizer(dsc.parameters(), hp['discriminator_optimizer'])\n",
    "    gen_optimizer = create_optimizer(gen.parameters(), hp['discriminator_optimizer'])\n",
    "\n",
    "\n",
    "def dsc_loss_fn(y_data, y_generated):\n",
    "    return discriminator_loss_fn(y_data, y_generated, hp['data_label'], hp['label_noise'])\n",
    "\n",
    "def gen_loss_fn(y_generated):\n",
    "    return generator_loss_fn(y_generated, hp['data_label'])\n",
    "\n",
    "def gen_wgan_loss(y_generated):\n",
    "    return gen_wgan_loss(y_generated,hp['data_label'])\n",
    "\n",
    "def dsc_wgan_loss(y_data, y_generated):\n",
    "    return dsc_wgan_loss(y_data, y_generated)\n",
    "\n",
    "def dsc_wgan_gp_loss(y_data, y_generated, dsc_model):\n",
    "    return dsc_wgan_gp_loss(y_generated, dsc_model)\n",
    "\n",
    "\n",
    "# Training\n",
    "checkpoint_file = 'checkpoints/wgan_sn_gp'\n",
    "checkpoint_file_final = f'{checkpoint_file}_final'\n",
    "if os.path.isfile(f'{checkpoint_file}.pt'):\n",
    "    os.remove(f'{checkpoint_file}.pt')\n",
    "\n",
    "# Show hypers\n",
    "hp['batch_size'] = 64\n",
    "hp['discriminator_optimizer']['betas'] = (0.0, 0.9)\n",
    "\n",
    "print(hp)\n",
    "\n",
    "print(vanilla, wgan, spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-22T10:39:52.842884Z",
     "iopub.status.busy": "2021-01-22T10:39:52.842261Z",
     "iopub.status.idle": "2021-01-22T10:39:52.915161Z",
     "shell.execute_reply": "2021-01-22T10:39:52.915772Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import IPython.display\n",
    "import tqdm\n",
    "\n",
    "num_epochs = 1000\n",
    "n_cpu = 1\n",
    "latent_dim = 100\n",
    "img_size = 28\n",
    "channels = 1\n",
    "n_critic = 5\n",
    "clip_value = 0.01\n",
    "vanilla = True\n",
    "wgan = False\n",
    "# mode = 'wgan' if wgan else 'vanilla'\n",
    "mode = 'wgan_gd'\n",
    "if vanilla:\n",
    "    gen_loss = gen_loss_fn\n",
    "    dsc_loss = dsc_loss_fn\n",
    "    \n",
    "elif wgan:\n",
    "    gen_loss = gen_wgan_loss\n",
    "    dsc_loss = dsc_wgan_loss\n",
    "\n",
    "if os.path.isfile(f'{checkpoint_file_final}.pt'):\n",
    "    print(f'*** Loading final checkpoint file {checkpoint_file_final} instead of training')\n",
    "    num_epochs = 0\n",
    "    gen = torch.load(f'{checkpoint_file_final}.pt', map_location=device)\n",
    "    checkpoint_file = checkpoint_file_final\n",
    "\n",
    "    \n",
    "try:\n",
    "    dsc_avg_losses, gen_avg_losses = [], []\n",
    "    for epoch_idx in range(num_epochs):\n",
    "        # We'll accumulate batch losses and show an average once per epoch.\n",
    "        dsc_losses, gen_losses = [], []\n",
    "        print(f'--- EPOCH {epoch_idx+1}/{num_epochs} ---')\n",
    "\n",
    "        with tqdm.tqdm(total=len(dl_train.batch_sampler), file=sys.stdout) as pbar:\n",
    "            for batch_idx, (x_data, _) in enumerate(dl_train):\n",
    "                critic = batch_idx % n_critic == 0\n",
    "                x_data = x_data.to(device)\n",
    "                dsc_loss, gen_loss = train_batch(\n",
    "                    dsc, gen,\n",
    "                    dsc_loss_fn, gen_loss_fn,\n",
    "                    dsc_optimizer, gen_optimizer,\n",
    "                    x_data,critic=critic, mode=mode)\n",
    "                if not gen_loss:\n",
    "                    gen_loss = gen_losses[-1]\n",
    "                dsc_losses.append(dsc_loss)\n",
    "                gen_losses.append(gen_loss)\n",
    "                pbar.update()\n",
    "        \n",
    "        dsc_avg_losses.append(np.mean(dsc_losses))\n",
    "        gen_avg_losses.append(np.mean(gen_losses))\n",
    "        print(f'Discriminator loss: {dsc_avg_losses[-1]}')\n",
    "        print(f'Generator loss:     {gen_avg_losses[-1]}')\n",
    "        \n",
    "        if epoch_idx % 15 == 0:\n",
    "            save_checkpoint(gen, dsc_avg_losses, gen_avg_losses, checkpoint_file+str(epoch_idx))\n",
    "            print(f'Saved checkpoint.')\n",
    "            \n",
    "#         if epoch_idx % 100 == 0:\n",
    "        samples = gen.sample(5, with_grad=False)\n",
    "        fig, _ = plot.tensors_as_images(samples.cpu(), figsize=(6,2))\n",
    "        IPython.display.display(fig)\n",
    "        plt.close(fig)\n",
    "except KeyboardInterrupt as e:\n",
    "    print('\\n *** Training interrupted by user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-22T10:39:52.919449Z",
     "iopub.status.busy": "2021-01-22T10:39:52.918958Z",
     "iopub.status.idle": "2021-01-22T10:39:53.599100Z",
     "shell.execute_reply": "2021-01-22T10:39:53.599684Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot images from best or last model\n",
    "if os.path.isfile(f'{checkpoint_file}.pt'):\n",
    "    gen = torch.load(f'{checkpoint_file}.pt', map_location=device)\n",
    "print('*** Images Generated from best model:')\n",
    "samples = gen.sample(n=15, with_grad=False).cpu()\n",
    "fig, _ = plot.tensors_as_images(samples, nrows=3, figsize=(6,6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
